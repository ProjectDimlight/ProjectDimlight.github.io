[
  {
    "icon": "/static/冯依曼.jpg",
    "title": "学历教育",
    "date": "23/03/21",
    "contents": "<p>我对现在的学历教育有点焦虑了。</p><p>焦虑的主要原因是，我一位上中专的朋友，凭借着对一切的极大兴趣自学成才，然后现在各方面水平（不光是对方的专业、我的专业、还有一切我所能接触到的学科）完爆我十条街了。我承认像他这样超凡的人一定是少数；我不知道为什么这位朋友通过什么样的方式学习获得了这样的才华，也不确定未来哪边能够走得更远。我也觉得没必要分析。</p><p>我仅仅是自顾自地焦虑而已。</p>"
  },
  {
    "icon": "/static/冯依曼.jpg",
    "title": "冯依曼天堂",
    "date": "23/03/20",
    "contents": "<p>虽然概率很小，但是仍然可能存在这么一个宇宙。</p><p>在这里，每一个人都有同样的外貌、同样的性格、同样的爱好。</p><p>她们都是冯依曼。</p><p>想必这里是魏潇承的天堂了吧。</p><p>然而阴差阳错地，意外来到这个宇宙的并不是魏潇承，而是他那背负着整个世界树命运的妹妹。</p>"
  },
  {
    "icon": "/static/冯依曼.jpg",
    "title": "语言模型",
    "date": "23/03/20",
    "contents": "<p>众所周知，机器学习是基于统计学的、经验主义的。最近火爆的所谓“语言模型”，无外乎是将文字囫囵吞枣地统计，然后像写八股一样地挤出来。没有知识图谱或者专家系统的支持，语言模型或许能理解符号系统中词汇与词汇之间的逻辑关联，却无法理解它所代表的内涵。换句话说，当今的语言模型，与一个刚刚学了几个专业术语、就在完全没有领会内涵的前提下疯狂念经的魔怔人相比，并没有什么两样。</p><p>然而，机器学习的实践中有一项重要的流程叫做反向传播。当输出的结果与预期不符合的时候，可以将估价函数关于输入的梯度反向传播到模型的参数当中去。用人话讲，就是“知错就改”。只要能够“反向传播”，哪怕只是经验主义、哪怕只是魔怔念经，也可以在长期的反馈中逐渐纠正自己的错误。哪怕是一个纯粹形而上的“语言模型”，也能够讲出人模人样的话来。</p><p>那么，这些什么“语言模型”，要淘汰的是什么样的人呢？它们淘汰的，将会是那些怎么也学不会“反向传播”的人。</p>"
  },
  {
    "icon": "/static/冯依曼.jpg",
    "title": "卖叙事电池的sol",
    "date": "23/03/18",
    "contents": "<p>sol启动了一节叙事电池。他看到了刷刷的笑容，但是幻象转瞬即逝。</p><p>sol又启动了一节。他看到刷刷向他伸出手，但是幻象转瞬即逝。</p><p>这时，天空中闪现了叙事引擎的光芒，EXP碎片如流星般坠落。sol借机启动了所有的叙事电池。一个全新的世界线在强大的愿望中诞生，刷刷拉着sol走向了民政局（？）</p><p>第二天，人们发现sol在自己床上__死了。</p>"
  }
]